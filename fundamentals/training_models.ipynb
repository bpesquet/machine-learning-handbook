{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Training models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition\n",
    "\n",
    "The representation learnt from data during training is called a **model**. It defines the relationship between inputs and outputs, and thus produces results from data. Most (but not all) ML systems are model-based.\n",
    "\n",
    "[![Extract from the book Hands-on Machine Learning with Scikit-Learn & TensorFlow by A. GÃ©ron](images/instance_model_learning.png)](https://github.com/ageron/handson-ml2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis function\n",
    "\n",
    "- $\\pmb{\\theta}$ (sometime noted $\\pmb{\\omega}$): model's internal parameters vector.\n",
    "- $h_\\theta()$: model's prediction function (*hypothesis function*), using the model parameters $\\pmb{\\theta}$ to define the relationship between features and labels.\n",
    "- $y'^{(i)}$ (sometimes noted $\\hat{y}^{(i)}$): hypothesis function output (model prediction).\n",
    "\n",
    "$$y'^{(i)} = h_\\theta(\\pmb{x}^{(i)})$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass classification\n",
    "\n",
    "* $\\pmb{y}^{(i)}$ et $\\pmb{y}'^{(i)}$ are vectors with as many elements as the number of predicted classes $K$.\n",
    "* $\\pmb{y}^{(i)}$ (the *ground truth*) is a **binary vector** of $K$ values. $y^{(i)}_k$ is equal to 1 if the $i$th sample's class corresponds to $k$, 0 otherwise.\n",
    "* $\\pmb{y}'^{(i)}$ is a **probability vector** of $K$ values, computed by the model. $y'^{(i)}_k$ represents the probability that the $i$th sample belongs to class $k$.\n",
    "\n",
    "$$\\pmb{y}^{(i)} = \\begin{pmatrix}\n",
    "       \\ y^{(i)}_1 \\\\\n",
    "       \\ y^{(i)}_2 \\\\\n",
    "       \\ \\vdots \\\\\n",
    "       \\ y^{(i)}_K\n",
    "     \\end{pmatrix} \\in \\pmb{R}^K\n",
    "\\;\\;\\;\n",
    "\\pmb{y}'^{(i)} = \\begin{pmatrix}\n",
    "       \\ y'^{(i)}_1 \\\\\n",
    "       \\ y'^{(i)}_2 \\\\\n",
    "       \\ \\vdots \\\\\n",
    "       \\ y'^{(i)}_K\n",
    "     \\end{pmatrix} \\in \\pmb{R}^K$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model lifecycle\n",
    "\n",
    "There are two (repeatable) phases:\n",
    "\n",
    "- **Training**: using training input samples, the model learns to find a relationship between features and labels.\n",
    "- **Inference**: the trained model is used to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "- Many ML models also have user-defined properties called **hyperparameters**.\n",
    "  - Examples: maximum depth of a decision tree, number oy layers of a neural network...\n",
    "- Contrary to internal parameters, they are not automatically updated during training.\n",
    "- The hyperparameters directly affect the model's performance and must be tweaked during the training and tuning steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition\n",
    "\n",
    "- $\\mathcal{L_{\\pmb{X, y}}(\\pmb{\\theta})}$, sometimes noted $\\mathcal{J_{\\pmb{X, y}}(\\pmb{\\theta})}$: **loss** (or **cost**) function that quantifies the difference, often called **error**, between expected results (called *ground truth*) and actual results computed by the model.\n",
    "- During model training, the input dataset $\\pmb{X}$ and the expected results $\\pmb{y}$ are treated as constants. The loss depends solely on the model parameters $\\pmb{\\theta}$. To simplify notations, the loss function will be written $\\mathcal{L(\\pmb{\\theta})}$.\n",
    "- Different loss functions exist. The choice depends on the learning type. See [Losses](./losses) for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition\n",
    "\n",
    "- Used during the training phase.\n",
    "- Objective: find the set of model parameters $\\pmb{\\theta}^{*}$ that minimizes the loss.\n",
    "- For each learning type, several algorithms of various complexity exist.\n",
    "\n",
    "[![Optimization: linear regression](images/LossSideBySide.png)](https://developers.google.com/machine-learning/crash-course/reducing-loss/an-iterative-approach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### An iterative approach\n",
    "\n",
    "The model's parameters are iteratively updated until an optimum is reached.\n",
    "\n",
    "[![Iterative approach](images/GradientDescentDiagram.png)](https://developers.google.com/machine-learning/crash-course/descending-into-ml/training-and-loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The gradient descent algorithm\n",
    "\n",
    "- Used in several ML models, including neural networks.\n",
    "- General idea: converging to a loss function's minimum by updating model parameters in small steps, in the **opposite direction** of the loss function **gradient**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The notion of gradient\n",
    "\n",
    "- Expresses the variation of a function relative to the variation of its parameters.\n",
    "- Vector containing partial derivatives of the function *w.r.t.* each of its $P$ parameters.\n",
    "\n",
    "$$\\nabla_{\\theta}\\mathcal{L}(\\boldsymbol{\\pmb{\\theta}}) = \\begin{pmatrix}\n",
    "       \\ \\frac{\\partial}{\\partial \\theta_1} \\mathcal{L}(\\boldsymbol{\\theta}) \\\\\n",
    "       \\ \\frac{\\partial}{\\partial \\theta_2} \\mathcal{L}(\\boldsymbol{\\theta}) \\\\\n",
    "       \\ \\vdots \\\\\n",
    "       \\ \\frac{\\partial}{\\partial \\theta_P} \\mathcal{L}(\\boldsymbol{\\theta})\n",
    "     \\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1D gradient descent (one parameter)\n",
    "\n",
    "![Gradient Descent](images/gradient_descent_1parameter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2D gradient (two parameters)\n",
    "\n",
    "![Tangent Space](images/tangent_space.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2D gradient descent\n",
    "\n",
    "![Gradient Descent](images/gradient_descent_2parameters.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gradient descent types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Batch Gradient Descent\n",
    "\n",
    "The gradient is computed on the whole dataset before model parameters are updated.\n",
    "\n",
    "- Advantages: simple and safe (always converges in the right direction).\n",
    "- Drawback: can become slow and even untractable with a big dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Stochastic Gradient Descent (SGD)\n",
    "\n",
    "The gradient is computed on only one randomly chosen sample whole dataset before parameters are updated.\n",
    "\n",
    "- Advantages:\n",
    "  - Very fast.\n",
    "  - Enables learning from each new sample (*online learning*).\n",
    "- Drawback:\n",
    "  - Convergence is not guaranteed.\n",
    "  - No vectorization of computations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mini-Batch SGD\n",
    "\n",
    "The gradient is computed on a small set of samples, called a *batch*, before parameters are updated.\n",
    "\n",
    "- Combines the advantages of batch and stochastic GD.\n",
    "- Default method for many ML libraries.\n",
    "- The mini-batch size varies between 10 and 1000 samples, depending of the dataset size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model parameters update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Learning rate\n",
    "\n",
    "$\\eta$ is the update factor for parameters once gradient is computed, called the **_learning rate_**.\n",
    "\n",
    "It has a direct impact on the \"speed\" of the gradient descent.\n",
    "\n",
    "$$\\pmb{\\theta_{next}} = \\pmb{\\theta} - \\eta\\nabla_{\\boldsymbol{\\theta}}\\mathcal{L}(\\boldsymbol{\\theta})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Importance of learning rate\n",
    "\n",
    "![Learning rate](images/learning_rate.png)\n",
    "\n",
    "[Interactive exercise](https://developers.google.com/machine-learning/crash-course/fitter/graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The local minima problem\n",
    "\n",
    "![Local minima](images/local_minima.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Gradient Descent](images/gd_ng.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Optimization algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient descent evolution map\n",
    "\n",
    "[![Gradient Descent evolution map](images/gradient_descent_evolution_map.png)](https://towardsdatascience.com/10-gradient-descent-optimisation-algorithms-86989510b5e9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Momentum\n",
    "\n",
    "Momentum optimization accelerates the descent speed in the direction of the minimum by accumulating previous gradients. It can also escape plateaux faster then plain GD.\n",
    "\n",
    "[![Momemtum demo](images/gd_momentum_demo.gif)](https://youtu.be/qPKKtvkVAjY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Momentum equations\n",
    "\n",
    "$$\\pmb{m_{k+1}} = \\beta_k \\pmb{m_k} - \\nabla_{\\boldsymbol{\\theta}}\\mathcal{L}(\\boldsymbol{\\theta_k})$$\n",
    "\n",
    "$$\\pmb{\\theta_{k+1}} = \\pmb{\\theta_k} + \\eta_k\\pmb{m_{k+1}}$$\n",
    "\n",
    "$\\beta_k \\in [0,1]$ is a friction factor that prevents gradients updates from growing too large. A typical value is 0.9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Momentum Vs plain GD\n",
    "\n",
    "[![Momentum Vs plain GD](images/gd_momentum.png)](https://youtu.be/kVU8zTI-Od0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### RMSprop\n",
    "\n",
    "*RMSprop* decays the learning rate differently for each parameter, scaling down the gradient vector along the steepest dimensions. The underlying idea is to adjust the descent direction a bit more towards the global minimum.\n",
    "\n",
    "$$\\pmb{v_{k+1}} = \\beta_k \\pmb{v_k} + (1-\\beta_k) \\left(\\nabla_{\\boldsymbol{\\theta}}\\mathcal{L}(\\boldsymbol{\\theta_k})\\right)^2$$\n",
    "\n",
    "$$\\pmb{\\theta_{k+1}} = \\pmb{\\theta_k} - \\frac{\\eta_k}{\\sqrt{\\pmb{v_{k}}+\\epsilon}}\\nabla_{\\boldsymbol{\\theta}}\\mathcal{L}(\\boldsymbol{\\theta_k})$$\n",
    "\n",
    "$\\epsilon$ is a smoothing term to avoid divisions by zero. A typical value is $10^{-10}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Adam and other techniques\n",
    "\n",
    "*Adam* (*Adaptive Moment Estimation*) combines the ideas of momentum and RMSprop. It is the *de facto* choice nowadays.\n",
    "\n",
    "Gradient descent optimization is a rich subfield of Machine Learning. Read more in [this article](http://ruder.io/optimizing-gradient-descent/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
